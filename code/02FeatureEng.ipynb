{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "#from sklearn.model_selection import cross_val_score, train_test_split \n",
    "#from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the dataframe\n",
    "\n",
    "df = pd.read_csv('../data/cleaned/combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220671, 260)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>post</th>\n",
       "      <th>tfidf_abl</th>\n",
       "      <th>tfidf_abus</th>\n",
       "      <th>tfidf_actual</th>\n",
       "      <th>tfidf_addict</th>\n",
       "      <th>tfidf_adhd</th>\n",
       "      <th>tfidf_advic</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_wish</th>\n",
       "      <th>tfidf_without</th>\n",
       "      <th>tfidf_wonder</th>\n",
       "      <th>tfidf_work</th>\n",
       "      <th>tfidf_worri</th>\n",
       "      <th>tfidf_wors</th>\n",
       "      <th>tfidf_would</th>\n",
       "      <th>tfidf_wrong</th>\n",
       "      <th>tfidf_x200b</th>\n",
       "      <th>tfidf_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alcoholism</td>\n",
       "      <td>RobynTacoo</td>\n",
       "      <td>2019/10/19</td>\n",
       "      <td>My husband offered me a glass of wine I turned...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alcoholism</td>\n",
       "      <td>wolsinyourarea</td>\n",
       "      <td>2019/10/19</td>\n",
       "      <td>Feeling like a failure Broke my 2 week streak ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alcoholism</td>\n",
       "      <td>glitterONeverything</td>\n",
       "      <td>2019/10/19</td>\n",
       "      <td>help! withdrawals are crazy!! I feel lije shit...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alcoholism</td>\n",
       "      <td>Collector420</td>\n",
       "      <td>2019/10/19</td>\n",
       "      <td>God damn I (M17) wrote messages to almost 20 p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alcoholism</td>\n",
       "      <td>engineerkoala</td>\n",
       "      <td>2019/10/19</td>\n",
       "      <td>How to have as much fun as before Today was my...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337441</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit               author        date  \\\n",
       "0  alcoholism           RobynTacoo  2019/10/19   \n",
       "1  alcoholism       wolsinyourarea  2019/10/19   \n",
       "2  alcoholism  glitterONeverything  2019/10/19   \n",
       "3  alcoholism         Collector420  2019/10/19   \n",
       "4  alcoholism        engineerkoala  2019/10/19   \n",
       "\n",
       "                                                post  tfidf_abl  tfidf_abus  \\\n",
       "0  My husband offered me a glass of wine I turned...        0.0         0.0   \n",
       "1  Feeling like a failure Broke my 2 week streak ...        0.0         0.0   \n",
       "2  help! withdrawals are crazy!! I feel lije shit...        0.0         0.0   \n",
       "3  God damn I (M17) wrote messages to almost 20 p...        0.0         0.0   \n",
       "4  How to have as much fun as before Today was my...        0.0         0.0   \n",
       "\n",
       "   tfidf_actual  tfidf_addict  tfidf_adhd  tfidf_advic  ...  tfidf_wish  \\\n",
       "0           0.0           0.0         0.0          0.0  ...    0.000000   \n",
       "1           0.0           0.0         0.0          0.0  ...    0.000000   \n",
       "2           0.0           0.0         0.0          0.0  ...    0.000000   \n",
       "3           0.0           0.0         0.0          0.0  ...    0.000000   \n",
       "4           0.0           0.0         0.0          0.0  ...    0.337441   \n",
       "\n",
       "   tfidf_without  tfidf_wonder  tfidf_work  tfidf_worri  tfidf_wors  \\\n",
       "0       0.479482           0.0         0.0          0.0         0.0   \n",
       "1       0.000000           0.0         0.0          0.0         0.0   \n",
       "2       0.000000           0.0         0.0          0.0         0.0   \n",
       "3       0.000000           0.0         0.0          0.0         0.0   \n",
       "4       0.000000           0.0         0.0          0.0         0.0   \n",
       "\n",
       "   tfidf_would  tfidf_wrong  tfidf_x200b  tfidf_year  \n",
       "0          0.0          0.0          0.0         0.0  \n",
       "1          0.0          0.0          0.0         0.0  \n",
       "2          0.0          0.0          0.0         0.0  \n",
       "3          0.0          0.0          0.0         0.0  \n",
       "4          0.0          0.0          0.0         0.0  \n",
       "\n",
       "[5 rows x 260 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape and the first 5 rows\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count sentences in each tweet (row)\n",
    "\n",
    "# set up an emty list for sentence counts\n",
    "\n",
    "n_sentence = []\n",
    "\n",
    "# iterate through the text column\n",
    "\n",
    "for i in range(len(df['post'])):\n",
    "    \n",
    "    n_sentence.append(len(sent_tokenize(df['post'][i].lower())))\n",
    "    \n",
    "# store it in the dataframe\n",
    "\n",
    "df['n_sentence'] = n_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate lemmatizer and tokenizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juhee/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "## tokenize and lemmatize\n",
    "\n",
    "# create a column 'text_clean'\n",
    "\n",
    "df['post_clean'] = ''\n",
    "\n",
    "# iterate through each row in the column text_all\n",
    "    \n",
    "for i in range(len(df['post'])):\n",
    "        \n",
    "    # tokenize each word in text into its own string\n",
    "    post_token = []\n",
    "    post_token.extend(tokenizer.tokenize(df['post'][i].lower()))\n",
    "    post_tokens = []\n",
    "    [post_tokens.append(word) for word in post_token if word not in post_tokens]\n",
    "        \n",
    "    # lemmatize the words\n",
    "    post_lemmatize = []\n",
    "    for j in range(len(post_tokens)):\n",
    "        post_lemmatize.append(lemmatizer.lemmatize(post_tokens[j]))\n",
    "        \n",
    "    # remove characters and numbers\n",
    "    clean_post = []\n",
    "    for k in range(len(post_lemmatize)):\n",
    "        clean_post.append(re.sub('[^a-zA-Z]', '', post_lemmatize[k]))    \n",
    "        \n",
    "    # group them together\n",
    "    post_collection = [post for post in clean_post]\n",
    "    \n",
    "    # put the words back to one long string\n",
    "    post_collection = ' '.join(post_collection)\n",
    "\n",
    "    # fill new column\n",
    "    df['post_clean'][i] = post_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count words in each tweet (row)\n",
    "\n",
    "# set up an empty list for word counts\n",
    "\n",
    "n_words = []\n",
    "\n",
    "# iterate through the text column\n",
    "\n",
    "for i in range(len(df['post_clean'])):\n",
    "    \n",
    "    word_tokens = tokenizer.tokenize(df['post_clean'][i])\n",
    "    cnt = len(word_tokens)\n",
    "    n_words.append(cnt)\n",
    "    \n",
    "# store it in the dataframe\n",
    "\n",
    "df['n_words'] = n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>post_clean</th>\n",
       "      <th>n_sentence</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My husband offered me a glass of wine I turned...</td>\n",
       "      <td>my husband offered me a glass of wine i turned...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feeling like a failure Broke my 2 week streak ...</td>\n",
       "      <td>feeling like a failure broke my  week streak a...</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>help! withdrawals are crazy!! I feel lije shit...</td>\n",
       "      <td>help  withdrawal are crazy  i feel lije shit a...</td>\n",
       "      <td>7</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>God damn I (M17) wrote messages to almost 20 p...</td>\n",
       "      <td>god damn i m wrote message to almost  people b...</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How to have as much fun as before Today was my...</td>\n",
       "      <td>how to have a much fun before today wa my seco...</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220666</th>\n",
       "      <td>My worst fear came to life today. One of my fr...</td>\n",
       "      <td>my worst fear came to life today  one of frien...</td>\n",
       "      <td>6</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220667</th>\n",
       "      <td>***GROSS ANXIETY STORY*** help... This is real...</td>\n",
       "      <td>gross anxiety story  help  this is really gros...</td>\n",
       "      <td>7</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220668</th>\n",
       "      <td>Really need advice and help please The last mo...</td>\n",
       "      <td>really need advice and help please the last mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220669</th>\n",
       "      <td>Anxiety to live up in the tech industry I’m a ...</td>\n",
       "      <td>anxiety to live up in the tech industry i m a ...</td>\n",
       "      <td>24</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220670</th>\n",
       "      <td>My coping toolbox I’m writing this partly for ...</td>\n",
       "      <td>my coping toolbox i m writing this partly for ...</td>\n",
       "      <td>33</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220671 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  \\\n",
       "0       My husband offered me a glass of wine I turned...   \n",
       "1       Feeling like a failure Broke my 2 week streak ...   \n",
       "2       help! withdrawals are crazy!! I feel lije shit...   \n",
       "3       God damn I (M17) wrote messages to almost 20 p...   \n",
       "4       How to have as much fun as before Today was my...   \n",
       "...                                                   ...   \n",
       "220666  My worst fear came to life today. One of my fr...   \n",
       "220667  ***GROSS ANXIETY STORY*** help... This is real...   \n",
       "220668  Really need advice and help please The last mo...   \n",
       "220669  Anxiety to live up in the tech industry I’m a ...   \n",
       "220670  My coping toolbox I’m writing this partly for ...   \n",
       "\n",
       "                                               post_clean  n_sentence  n_words  \n",
       "0       my husband offered me a glass of wine i turned...           2       17  \n",
       "1       feeling like a failure broke my  week streak a...           3       23  \n",
       "2       help  withdrawal are crazy  i feel lije shit a...           7       48  \n",
       "3       god damn i m wrote message to almost  people b...           2       66  \n",
       "4       how to have a much fun before today wa my seco...           5       62  \n",
       "...                                                   ...         ...      ...  \n",
       "220666  my worst fear came to life today  one of frien...           6       87  \n",
       "220667  gross anxiety story  help  this is really gros...           7      108  \n",
       "220668  really need advice and help please the last mo...           1       60  \n",
       "220669  anxiety to live up in the tech industry i m a ...          24      207  \n",
       "220670  my coping toolbox i m writing this partly for ...          33      261  \n",
       "\n",
       "[220671 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see if the columns have been created\n",
    "\n",
    "df[['post', 'post_clean', 'n_sentence', 'n_words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## count each character without white space in each tweet (row) to calculate readability index\n",
    "\n",
    "# set up an empty list for character counts\n",
    "\n",
    "n_chars = []\n",
    "\n",
    "# iterate through the text column\n",
    "\n",
    "for i in range(len(df['post_clean'])):\n",
    "    \n",
    "    n_chars.append(len(df['post_clean'][i].strip()))\n",
    "    \n",
    "# store it in the dataframe\n",
    "\n",
    "df['n_chars'] = n_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     88\n",
       "1    122\n",
       "2    250\n",
       "3    343\n",
       "4    331\n",
       "Name: n_chars, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['n_chars'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.webfx.com/tools/read-able/automated-readability-index.html#:~:text=Readability%20indices%20also%20take%20into,words%2Fsentences)%20%2D%2021.43.\n",
    "# calculate automated readability index \n",
    "\n",
    "df['ari'] = round((4.71 * (df['n_chars']/df['n_words']) + 0.5 * (df['n_words']/df['n_sentence']) - 21.43), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7.20\n",
       "1     7.39\n",
       "2     6.53\n",
       "3    19.55\n",
       "4     9.92\n",
       "Name: ari, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ari'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final file to csv\n",
    "\n",
    "df.to_csv('../data/cleaned/final.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
